{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## With Hadoop hdfs\n",
    "# remote (on docker) mlflow-server\n",
    "# remote(on docker) postgresql for backend-store\n",
    "# remote(on docker) hdfs for artifact-store. But Hadoop will be installed on locally because pyarrow needs to some hadoop file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='hdfs://localhost:9000/Models/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HADOOP_HOME'] = '/home/hdoop/hadoop'\n",
    "os.environ['ARROW_LIBHDFS_DIR'] = '/home/hdoop/hadoop/lib/native'\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "print(mlflow.list_experiments())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/05 18:29:29 INFO mlflow.tracking.fluent: Experiment with name 'Remote_Postgresql-Local_Hdfs-Local-Mlflow' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdfs://localhost:9000/Models/1/c836fa1e7eba46e1bc9a0353c28530f5/artifacts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmucahitnas/anaconda3/envs/MLOps/lib/python3.8/site-packages/mlflow/store/artifact/hdfs_artifact_repo.py:182: FutureWarning: pyarrow.hdfs.connect is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  connected = pa.hdfs.connect(\n",
      "2022-11-05 18:29:31,217 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2022-11-05 18:29:31,274 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2022-11-05 18:29:31,288 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2022-11-05 18:29:31,310 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2022-11-05 18:29:31,324 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default artifact URI: hdfs://localhost:9000/Models/1/c836fa1e7eba46e1bc9a0353c28530f5/artifacts\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlflow.set_experiment(\"Remote_Postgresql-Local_Hdfs-Local-Mlflow\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    print(mlflow.get_artifact_uri())\n",
    "\n",
    "    x, y = load_iris(return_X_y=True)\n",
    "\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    mlflow.log_param('Params',params)\n",
    "\n",
    "    lr = LogisticRegression(**params)\n",
    "    lr = lr.fit(x, y)\t\n",
    "\t\n",
    "    y_pred = lr.predict(x)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "\t\n",
    "    mlflow.sklearn.log_model(lr, artifact_path='')\n",
    "    print(f'default artifact URI: {mlflow.get_artifact_uri()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow\n",
    "\n",
    "os.environ['HADOOP_HOME'] = '/home/mmucahitnas/Downloads/hadoop-3.3.3/'\n",
    "os.environ['ARROW_LIBHDFS_DIR'] = '/home/mmucahitnas/Downloads/lib/native'\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "\n",
    "hdfs = pyarrow.hdfs.connect(host='172.17.0.2', port=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs.ls('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AWS\n",
    "\n",
    "# Remote ec2 server for mlflow-server\n",
    "# Remote Postgresql for backends-store\n",
    "# Remote S3 for artifacts-store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "TRACKING_SERVER_HOST = \"ec2-44-203-192-141.compute-1.amazonaws.com\"\n",
    "mlflow.set_tracking_uri(f'http://{TRACKING_SERVER_HOST}:5000')\n",
    "\n",
    "f'tracking URI: {mlflow.get_tracking_uri()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlflow.set_experiment(\"S3-Postgresql-Remote-AWS\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    print(mlflow.get_artifact_uri())\n",
    "\n",
    "    x, y = load_iris(return_X_y=True)\n",
    "\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    # mlflow.log_param(params)\n",
    "\n",
    "    lr = LogisticRegression(**params)\n",
    "    lr = lr.fit(x, y)\t\n",
    "\t\n",
    "    y_pred = lr.predict(x)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "\t\n",
    "    mlflow.sklearn.log_model(lr, artifact_path='Models')\n",
    "    print(f'default artifact URI: {mlflow.get_artifact_uri()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('MLOps': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04a4bbd8b88420370b6df19645b8f9743dc60bbdffd861ceacad4224d646d669"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
