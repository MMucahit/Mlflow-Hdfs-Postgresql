{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## With Hadoop hdfs\n",
    "# remote (on docker) mlflow-server\n",
    "# remote(on docker) postgresql for backend-store\n",
    "# remote(on docker) hdfs for artifact-store. But Hadoop will be installed on locally because pyarrow needs to some hadoop file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'])\n",
    "    df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe(\"./data/green_tripdata_2022-01.parquet\")\n",
    "df_val = read_dataframe(\"./data/green_tripdata_2022-02.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']\n",
    "\n",
    "\n",
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HADOOP_HOME'] = '/home/hdoop/hadoop'\n",
    "os.environ['ARROW_LIBHDFS_DIR'] = '/home/hdoop/hadoop/lib/native'\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "print(mlflow.list_experiments())\n",
    "\n",
    "mlflow.set_experiment(\"Mlflow-Xgboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train = xgb.DMatrix(X_train, label = y_train)\n",
    "valid = xgb.DMatrix(X_val, label = y_val)\n",
    "\n",
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\",\"xgboost\") ## Set Tag\n",
    "        mlflow.log_params(params) ## Log Param\n",
    "        booster = xgb.train(\n",
    "            params = params,\n",
    "            dtrain = train,\n",
    "            num_boost_round = 10,\n",
    "            evals = [(valid, \"validation\")],\n",
    "            early_stopping_rounds = 3\n",
    "        )\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared = False)\n",
    "        mlflow.log_metric(\"rmse\", rmse) ## Log Metric\n",
    "\n",
    "        mlflow.xgboost.log_model(booster, artifact_path='Models') ## Log Model\n",
    "\n",
    "    return {\"loss\": rmse, \"status\": STATUS_OK}\n",
    "\n",
    "search_space = {\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 4, 100, 1)),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", -3, 0),\n",
    "    \"reg_alpha\": hp.loguniform(\"reg_alpha\", -5, -1),\n",
    "    \"reg_lambda\": hp.loguniform(\"reg_lambda\", -6, -1),\n",
    "    \"min_child_weight\": hp.loguniform(\"min_child_weight\", -1, 3),\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"seed\": 55,\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn= objective,\n",
    "    space=search_space,\n",
    "    algo= tpe.suggest,\n",
    "    max_evals= 20,\n",
    "    trials= Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 15:27:48,806 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:27:48] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[ 6.578524   3.3540823 24.625639  37.48502   27.982061   9.45252\n",
      " 22.10602    3.8870816 14.812214   5.626942 ]\n"
     ]
    }
   ],
   "source": [
    "## Load Model\n",
    "\n",
    "model_id = \"81f4efd12151425189ebc9653d8bdeb9\"\n",
    "logged_model = f\"runs:/{model_id}/Models\"\n",
    "\n",
    "# There are two ways for load model\n",
    "\n",
    "# loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "## There is an error because of Xgboost.DMatrix\n",
    "# print(loaded_model.predict(valid)[:10]) \n",
    "\n",
    "xgboost_model = mlflow.xgboost.load_model(logged_model)\n",
    "print(xgboost_model.predict(valid)[:10]) ## Object of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Autolog\n",
    "\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "train = xgb.DMatrix(X_train, label = y_train)\n",
    "valid = xgb.DMatrix(X_val, label = y_val)\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.5708688941546396,\n",
    "    'max_depth': 16,\n",
    "    'min_child_weight': 0.3907249417416627,\n",
    "    'objective': 'reg:linear',\n",
    "    'reg_alpha': 0.016943269004007114,\n",
    "    'reg_lambda': 0.1796292504048719,\n",
    "    'seed':\t55\n",
    "}\n",
    "\n",
    "booster = xgb.train(\n",
    "            params = params,\n",
    "            dtrain = train,\n",
    "            num_boost_round = 500,\n",
    "            evals = [(valid, \"validation\")],\n",
    "            early_stopping_rounds = 50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AWS\n",
    "\n",
    "# Remote ec2 server for mlflow-server\n",
    "# Remote Postgresql for backends-store\n",
    "# Remote S3 for artifacts-store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "TRACKING_SERVER_HOST = \"ec2-44-203-192-141.compute-1.amazonaws.com\"\n",
    "mlflow.set_tracking_uri(f'http://{TRACKING_SERVER_HOST}:5000')\n",
    "\n",
    "f'tracking URI: {mlflow.get_tracking_uri()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlflow.set_experiment(\"S3-Postgresql-Remote-AWS\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    print(mlflow.get_artifact_uri())\n",
    "\n",
    "    x, y = load_iris(return_X_y=True)\n",
    "\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    # mlflow.log_param(params)\n",
    "\n",
    "    lr = LogisticRegression(**params)\n",
    "    lr = lr.fit(x, y)\t\n",
    "\t\n",
    "    y_pred = lr.predict(x)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "\t\n",
    "    mlflow.sklearn.log_model(lr, artifact_path='Models')\n",
    "    print(f'default artifact URI: {mlflow.get_artifact_uri()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.list_experiments()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('MLOps': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04a4bbd8b88420370b6df19645b8f9743dc60bbdffd861ceacad4224d646d669"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
